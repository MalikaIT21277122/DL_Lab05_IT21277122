{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DulanWeerasekara/DL_Lab5/blob/main/IT21193804Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 - Implementing LSTM for Time-Series Forecasting**\n",
        "\n",
        "\n",
        "***Read the following descriptions and instructions***\n",
        "\n",
        "Time-series forecasting is a crucial task in various fields, including finance, economics, and weather prediction. In this question, you'll work with Long Short-Term Memory (LSTM) networks, a type of recurrent neural network (RNN) that is particularly effective at learning from sequences of data. LSTMs are designed to capture long-term dependencies in time-series data, making them well-suited for predicting future values based on historical patterns.\n",
        "\n",
        "In this task, you will implement an LSTM model to forecast stock prices using historical data. Specifically, you'll use the closing prices of a stock to predict future prices, which is a common real-world application of time-series analysis in financial markets. This exercise will help you understand the principles of sequence modeling and how LSTMs can be applied to complex prediction tasks."
      ],
      "metadata": {
        "id": "MyWFUEnRajzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yEY1J0Bgc51",
        "outputId": "da5cf7bf-202a-425c-aa01-4014dc9fa9f6"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "vKdTBHBbadlb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and Preprocess the Data\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df['Close'].values  # Use the 'Close' price for prediction"
      ],
      "metadata": {
        "id": "O9Y2p8k0aq4d"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Prepare the Dataset for LSTM\n",
        "def create_dataset(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        X.append(data[i:(i + time_step)])\n",
        "        y.append(data[i + time_step])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "224EeqW6auK7"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "file_path = '/content/GOOG.csv'  # Path to the dataset in Colab or Jupyter home directory\n",
        "data = load_data(file_path)"
      ],
      "metadata": {
        "id": "KaH4F3mvazKH"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the Data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data.reshape(-1, 1)).reshape(-1)"
      ],
      "metadata": {
        "id": "3SdZRCc0a51M"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**time_step = 60:** This variable defines the length of the input sequence, meaning we will use the past 60 days of stock prices to predict the next day's closing price. This value is chosen to capture enough historical information to make an accurate prediction. You can change and try"
      ],
      "metadata": {
        "id": "7Khqb1qD5IsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the Dataset\n",
        "time_step = 60  # Using 60 days of data to predict the next day's price\n",
        "X, y = create_dataset(data, time_step)"
      ],
      "metadata": {
        "id": "QmXBUdova9GP"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for LSTM input [samples, time steps, features]\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)"
      ],
      "metadata": {
        "id": "QMA5jpNnbA9a"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Data into Training and Testing Sets (80% train, 20% test)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]"
      ],
      "metadata": {
        "id": "ErOC_sJdbEMe"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Modify the number of units in the LSTM layers and consider adding more layers or changing the dropout rate to see how these adjustments affect the model's performance***\n",
        "\n",
        "Experiment with 'units'\n",
        "\n",
        "Experiment with dropout for regularization\n",
        "\n",
        "Add another LSTM layer\n",
        "\n"
      ],
      "metadata": {
        "id": "kOWw9rEX5awq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define the LSTM Model\n",
        "model = Sequential()\n",
        "\n",
        "# --- Students: Modify the number of LSTM layers and units to experiment with model complexity ---\n",
        "model.add(LSTM(units=115, return_sequences=True, input_shape=(time_step, 1)))  # <-- Experiment with 'units'\n",
        "model.add(Dropout(0.2))  # Experiment with dropout for regularization\n",
        "\n",
        "model.add(LSTM(units=50, return_sequences=False))  # <-- Add another LSTM layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58PjSxibbKWV",
        "outputId": "96d4ba4d-d642-42ed-9a04-e3cf14b6ff5e"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Adjust the epochs and batch_size during the training phase to optimize the model’s learning process and its ability to generalize.***"
      ],
      "metadata": {
        "id": "GxH3rJwb6EIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train the Model\n",
        "\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1)  # <-- Experiment with 'epochs' and 'batch_size'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAVwfLj7bTcL",
        "outputId": "87790be9-0ab2-40c5-ffc8-c233217a0887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 306ms/step - loss: 0.4498\n",
            "Epoch 2/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.1457\n",
            "Epoch 3/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - loss: 0.1794\n",
            "Epoch 4/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - loss: 0.1195\n",
            "Epoch 5/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - loss: 0.1515\n",
            "Epoch 6/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - loss: 0.1102\n",
            "Epoch 7/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - loss: 0.1084\n",
            "Epoch 8/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1040\n",
            "Epoch 9/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0949\n",
            "Epoch 10/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1174\n",
            "Epoch 11/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1030\n",
            "Epoch 12/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0876\n",
            "Epoch 13/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1065\n",
            "Epoch 14/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0886\n",
            "Epoch 15/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1021\n",
            "Epoch 16/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - loss: 0.0929\n",
            "Epoch 17/200\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - loss: 0.0961\n",
            "Epoch 18/200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Predict on the Test Data\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "n4BCFz26bYVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse transform to get the original scale\n",
        "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1)\n",
        "y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(-1)"
      ],
      "metadata": {
        "id": "m434kbHBbcob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Analyze the plot to evaluate the model performance. Consider modifying the model architecture or training parameters to improve accuracy***"
      ],
      "metadata": {
        "id": "gLyRbsMZ6Q_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Plot the Results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test, label='Actual')\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.title('LSTM Stock Price Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "1maQ_edkbfqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Answer the following questions. (You can type answers in a text cell)***\n",
        "1.\tWhat is the purpose of normalizing the 'Close' prices before feeding them into the LSTM model?\n",
        "2.\tWhat is the purpose of the Dropout layer in the LSTM model?\n",
        "3.\tIn the plot showing actual vs predicted stock prices, what does it indicate if the predicted line closely follows the actual line?\n"
      ],
      "metadata": {
        "id": "PGvJoaLY6eWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why normalize 'Close' prices?**\n",
        "\n",
        "To scale the data, which helps the model learn better and faster, and prevents issues like exploding or vanishing gradients.\n",
        "\n",
        "**Purpose of Dropout layer?**\n",
        "\n",
        "To prevent overfitting by randomly dropping some neurons during training, making the model more robust.\n",
        "\n",
        "**What does it mean if the predicted line closely follows the actual line?**\n",
        "\n",
        "It indicates that the model is accurate and has learned the patterns in the data well."
      ],
      "metadata": {
        "id": "0-a3Pmnpj8ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Normalizing 'Close' prices: Explain that normalization helps in scaling the data within a specific range, which aids in faster convergence and prevents the model from being biased towards larger numbers.\n",
        "\n",
        "2) Dropout layer: Describe how it helps prevent overfitting by randomly dropping a set of neurons during training.\n",
        "\n",
        "3) Plot Analysis: If the predicted line closely follows the actual line, it indicates that the model is learning effectively and making accurate predictions."
      ],
      "metadata": {
        "id": "thwzUIU0kM7x"
      }
    }
  ]
}